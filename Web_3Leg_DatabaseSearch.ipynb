{
 "cells": [
  {
   "cell_type": "raw",
   "id": "65e0fed7",
   "metadata": {},
   "source": [
    "Script for accessing and searching the 3-leg branewebs databases\n",
    "\n",
    "The data is formatted in a single list, such that the 1st list dimension indicates the weak-equivalence classes (with the same invariants), the 2nd dimension indicates the strong-equivalence classes within each weak class (those that can be mutated to each other after a series of SL(2,Z) and Hanay-Witten moves), and the 3rd dimension lists the actual webs in each strong class.    \n",
    "...i.e. each list entry is a weak-equivalence class, each of those containing sublists corresponding to each strong-equivalence class, and each of those then containing a list of 3x3 web matrices.\n",
    "\n",
    "The webs are formatted as 3x3 arrays:\n",
    "[[p1, p2, p3],\n",
    " [q1, q2, q3],\n",
    " [m1, m2, m3]]    \n",
    "...for each of the 3 (p,q) web legs with multiplicity m\n",
    "\n",
    "After importing the data, this script is split into 3 parts:    \n",
    "1) Identify if an input web conserves charge, and compute its invariants (rank, total monodormy matrix trace, asymptotic charge).    \n",
    "2) Identify if an input web exists in the database, and return a random sample of strongly-equivalent webs.    \n",
    "3) Compare the equivalence of 2 input webs (whether strong-equivalent, weak-equivalent (hence also strong), or not in the database).\n",
    "\n",
    "Before running please download this file with the respective dataset, unzip the data, and update the filepath in the next cell. Then one can manually input webs and run the subsequent cells as they wish.    \n",
    "\n",
    "Database Generation information:    \n",
    "The databases are generated by producing all consistent webs in the range of (p,q) values [-a,a] and m values [1,b], computing their invariants and sorting them into weak-equivalence classes. Then for each weak-equivalence classes a web is taken and a strong-strong equivalence class generated for it by performing d steps. In each step all SL(2,Z) matrices with entries in the range [-c,c] are applied to the webs, then Hanany-Witten moves are applied to each of the legs. All new webs are saved, discarding any which are inconsistent or have an entry outside of the range [-e,e]. Once the first strong class is generated the next web in the weak class which is not already in a previous strong class now has its own strong class generated (if there are any repeats with a previous strong class these classes are later combined). The data is saved with the filename 'WebData[a, b, c, d, e].pickle'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63c55d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of webs: 1002396\n"
     ]
    }
   ],
   "source": [
    "### This cell imports the required libraries, the selected dataset, outputs the dataset size, and defines the necessary functions for searching it.\n",
    "#Import libraries\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Load data (binarised)\n",
    "with open('./WebData_[5, 5, 5, 2, 100].pickle','rb') as file: #...ensure this filepath is correct for the dataset one wishes to search\n",
    "    Data = pickle.load(file)\n",
    "\n",
    "#Count number of webs\n",
    "web_count = 0\n",
    "for wc in Data:\n",
    "    for sc in wc: web_count += len(sc)\n",
    "print(f'Number of webs: {web_count}')\n",
    "del(file,wc,sc)\n",
    "\n",
    "#Define function to search database for an input web, returning its position in the database\n",
    "def ReturnWebClass(web):\n",
    "    for wc in range(len(Data)):\n",
    "        for sc in range(len(Data[wc])):\n",
    "            for w in range(len(Data[wc][sc])):\n",
    "                if np.array_equal(Data[wc][sc][w],web): \n",
    "                    return (wc,sc,w)\n",
    "    return 'web not present'\n",
    "\n",
    "#Define a function to order the web's legs in a consistent manner (anticlockwise from the -p axis) --> more efficient data storage and searching\n",
    "def anticlockwise_websort(web):\n",
    "    angles = [np.arctan2(web[1,0],web[0,0]),np.arctan2(web[1,1],web[0,1]),np.arctan2(web[1,2],web[0,2])] \n",
    "    return np.vstack(list(zip(*sorted(zip(angles,web.transpose()),key=lambda x: x[0])))[1]).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a62b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web rank: 9.0\n",
      "Web total monodromy trace: 402\n",
      "Web asymptotic charge: 5\n"
     ]
    }
   ],
   "source": [
    "### (1) Return the invariants of a web (i.e. for the full weak class)\n",
    "#Define input web\n",
    "input_web = [[-7, 11, -1], [-3,  4,  1], [ 3,  2,  1]]  #...input format [[p1,p2,p3],[q1,q2,q3],[m1,m2,m3]]\n",
    "#Convert web to an array, and sort its legs\n",
    "input_web = anticlockwise_websort(np.array(input_web,dtype='int'))\n",
    "\n",
    "#Check if the web conserves (p,q) charge\n",
    "if input_web[0][0]*input_web[2][0] + input_web[0][1]*input_web[2][1] + input_web[0][2]*input_web[2][2] != 0 or input_web[1][0]*input_web[2][0] + input_web[1][1]*input_web[2][1] + input_web[1][2]*input_web[2][2] != 0:\n",
    "    print('Error: (p,q) charge not conserved for the web')\n",
    "#Check the web is displayed with all (p,q) coprime --> correct it to if not\n",
    "for leg_idx in range(3):\n",
    "    if abs(np.gcd(input_web[0][leg_idx],input_web[1][leg_idx])) != 1:\n",
    "        print('Error: Leg '+str(leg_idx+1)+' (p,q) values not coprime, correcting web...')\n",
    "        factor = abs(np.gcd(input_web[0][leg_idx],input_web[1][leg_idx]))\n",
    "        input_web[2][leg_idx] *= factor\n",
    "        input_web[0][leg_idx] = int(input_web[0][leg_idx]/factor)\n",
    "        input_web[1][leg_idx] = int(input_web[1][leg_idx]/factor)\n",
    "        \n",
    "#Compute the web rank\n",
    "I = abs(input_web[0][0]*input_web[2][0]*input_web[1][1]*input_web[2][1]-input_web[0][1]*input_web[2][1]*input_web[1][0]*input_web[2][0] + input_web[0][0]*input_web[2][0]*input_web[1][2]*input_web[2][2]-input_web[0][2]*input_web[2][2]*input_web[1][0]*input_web[2][0] + input_web[0][1]*input_web[2][1]*input_web[1][2]*input_web[2][2]-input_web[0][2]*input_web[2][2]*input_web[1][1]*input_web[2][1]) - (input_web[2][0]**2 + input_web[2][1]**2 + input_web[2][2]**2)\n",
    "web_rank = (I+2)/2\n",
    "print(f'Web rank: {web_rank}')\n",
    "\n",
    "#Compute the web total monodromy trace\n",
    "M1 = np.array([[1+input_web[0][0]*input_web[1][0],-input_web[0][0]**2],[input_web[1][0]**2,1-input_web[0][0]*input_web[1][0]]]) #...monodormy for leg 1\n",
    "M2 = np.array([[1+input_web[0][1]*input_web[1][1],-input_web[0][1]**2],[input_web[1][1]**2,1-input_web[0][1]*input_web[1][1]]]) #...monodormy for leg 2\n",
    "M3 = np.array([[1+input_web[0][2]*input_web[1][2],-input_web[0][2]**2],[input_web[1][2]**2,1-input_web[0][2]*input_web[1][2]]]) #...monodormy for leg 3\n",
    "web_monodromy_trace = np.matrix.trace(np.matmul(M3,np.matmul(M2,M1)))\n",
    "print(f'Web total monodromy trace: {web_monodromy_trace}')\n",
    "\n",
    "#Compute the web asymptotic charge\n",
    "web_asymptotic_charge = abs(np.gcd.reduce([input_web[0][0]*input_web[1][1] - input_web[0][1]*input_web[1][0],input_web[0][0]*input_web[1][2] - input_web[0][2]*input_web[1][0],input_web[0][1]*input_web[1][2] - input_web[0][2]*input_web[1][1]]))\n",
    "print(f'Web asymptotic charge: {web_asymptotic_charge}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592865e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The indices to denote the web position in the database are: (2, 0, 55)\t--> (weak class index, strong class index, strong class position)\n",
      "\n",
      "#####################\n",
      "\n",
      "Sample strong eqivalent webs:\n",
      "[[  3   3 -31]\n",
      " [ -1   4   7]\n",
      " [ 29   2   3]]\n",
      "\n",
      "[[-1  3  2]\n",
      " [-5  5 15]\n",
      " [ 7  1  2]]\n",
      "\n",
      "[[ 45  15  -5]\n",
      " [-29  -2   3]\n",
      " [  7   2  69]]\n",
      "\n",
      "[[ 14   3 -49]\n",
      " [-25  -5  85]\n",
      " [  2   7   1]]\n",
      "\n",
      "[[  3 -19  -1]\n",
      " [-11  73   2]\n",
      " [  7   1   2]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### (2) Return the class of equivalent webs for an input web\n",
    "#Define input web\n",
    "input_web = [[-7, 11, -1], [-3,  4,  1], [ 3,  2,  1]]  #...input format [[p1,p2,p3],[q1,q2,q3],[m1,m2,m3]]\n",
    "#Convert web to an array, and sort its legs\n",
    "input_web = anticlockwise_websort(np.array(input_web,dtype='int'))\n",
    "\n",
    "#Identify the web's position in the database\n",
    "web_position = ReturnWebClass(input_web)\n",
    "print(f'The indices to denote the web position in the database are: {web_position}\\t--> (weak class index, strong class index, strong class position)',end='\\n\\n#####################\\n\\nSample strong eqivalent webs:\\n')\n",
    "\n",
    "#Print a sample of webs strongly equivalent to the input web, change number to return with the 'size' option\n",
    "for web in np.random.choice(range(len(Data[web_position[0]][web_position[1]])), size=5, replace=False):\n",
    "    print(Data[web_position[0]][web_position[1]][web],end='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b6089b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webs WEAK equivalent (but not strong equivalent)\n",
      "\n",
      "Data indexes: web 1 --> (113, 0, 1444), web 2 --> (113, 1, 965)\n"
     ]
    }
   ],
   "source": [
    "### (3) Return whether 2 inputs webs are strong/weak equivalent\n",
    "#Define input webs, format: [[p1,p2,p3],[q1,q2,q3],[m1,m2,m3]]\n",
    "input_web_1 = [[ 79,  14, -73], [-18,  -3,  16], [  1,  10,   3]]\n",
    "input_web_2 = [[ -1,  -7,  19], [ -4, -53,  91], [ 74,   3,   5]]\n",
    "#Convert webs to arrays, and sort their legs\n",
    "input_web_1, input_web_2 = anticlockwise_websort(np.array(input_web_1,dtype='int')), anticlockwise_websort(np.array(input_web_2,dtype='int'))\n",
    "\n",
    "#Find the webs in the database\n",
    "web1_position = ReturnWebClass(input_web_1)\n",
    "web2_position = ReturnWebClass(input_web_2)\n",
    "\n",
    "#Output the equivalences\n",
    "if isinstance(web1_position,str) or isinstance(web2_position,str): \n",
    "    print('...cannot confirm equivalences as webs outside used dataset')\n",
    "else:\n",
    "    if web1_position[:2] == web2_position[:2]:\n",
    "        print('Webs STRONG equivalent (and hence weak equivalent also)')\n",
    "    elif web1_position[0] == web2_position[0]:\n",
    "        print('Webs WEAK equivalent (but not strong equivalent)')\n",
    "    else: \n",
    "        print('Webs NOT strong or weak equivalent')\n",
    "\n",
    "print(f'\\nData indexes: web 1 --> {web1_position}, web 2 --> {web2_position}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8731b985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
